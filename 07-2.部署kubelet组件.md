# 07-2.部署kubelet 组件

- kublet运行在每个worker节点上,接收kube-apiserver发送的请求,管理Pod容器,执行交互式命令,如 exec,run,logs等。
- kublet启动时自动向kube-apiserver注册节点信息,内置的cadvisor统计和监控节点的资源使用情况.为确保安全,只开启接收https请求的安全端口,对请求进行认证和授权,拒绝未授权的访问(如apiserver,heapster).

## 下载和分发kubelet

参考:06-0.master节点部署.md

## 安装依赖包

参考:07-0.部署worker节点.md

## 配置kubelet
脚本:07.02.kubelet-config.sh
### kubelet bootstrap kubeconfig 文件

```bash
info "create bootstrap kubeconfig ....."
[ ! -d /opt/k8s/certs/kubelet ] && mkdir -p /opt/k8s/certs/kubelet
cd /opt/k8s/certs/kubelet || return
source /opt/k8s/bin/environment.sh

for node_name in "${WORKER_NAMES[@]}"
  do
    echo ">>> ${node_name}"
    # create  token
     BOOTSTRAP_TOKEN=$(kubeadm token create \
      --description kubelet-bootstrap-token \
      --groups system:bootstrappers:${node_name} \
      --kubeconfig ~/.kube/config)
      export BOOTSTRAP_TOKEN
    # 设置集群参数
    kubectl config set-cluster kubernetes \
      --certificate-authority=/etc/kubernetes/cert/ca.pem \
      --embed-certs=true \
      --server=${KUBE_APISERVER} \
      --kubeconfig=kubelet-bootstrap-${node_name}.kubeconfig
    # 设置客户端认证参数
    kubectl config set-credentials kubelet-bootstrap \
      --token=${BOOTSTRAP_TOKEN} \
      --kubeconfig=kubelet-bootstrap-${node_name}.kubeconfig
    # 设置上下文参数
    kubectl config set-context default \
      --cluster=kubernetes \
      --user=kubelet-bootstrap \
      --kubeconfig=kubelet-bootstrap-${node_name}.kubeconfig
    # 设置默认上下文
    kubectl config use-context default --kubeconfig=kubelet-bootstrap-${node_name}.kubeconfig
  done

```
- 向kubeconfig写入的是token而非证书,bootstrap结束后kube-controller-manager为kubelet创建client和server 证书

查看kubeadm为各节点创建的token:

```bash
source /opt/k8s/bin/environment.sh
kubeadm token list --kubeconfig ~/.kube/config
```
- 创建的token有效期为1天,超期后将不能再被使用,且会被kube-controller-manager的tokencleaner清理(如果启用了该controller)
- kube-apiserver接收kubelet的bootstrap token后,将请求的user设置为system:bootstrap:<Token ID>,group设置为system:bootstrappers,后续将为这个 group 设置 ClusterRoleBinding

查看各token关联的Secret


```bash
kubectl get secrets  -n kube-system |grep bootstrap-token
```
### 分发bootstrap kubeconfig到所有worker节点


```bash
info "deploy bootstrap kubeconfig to all worker nodes ..... "
cd /opt/k8s/certs/kubelet || return
source /opt/k8s/bin/environment.sh
node_counts=${#WORKER_IPS[@]}
for (( i=0; i < $node_counts; i++ ))
do
   echo ">>> ${WORKER_NAMES[i]}"
   scp kubelet-bootstrap-${WORKER_NAMES[i]:?}.kubeconfig ${k8s_user:?}@${WORKER_IPS[i]:?}:/etc/kubernetes/kubelet-bootstrap.kubeconfig
done
```
### 创建和分发 kubelet 参数配置文件

#### 创建 kubelet 参数配置模板文件
可配置项参考[代码中注释](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/config/types.go)

```bash
cd /opt/k8s
cd /opt/k8s/certs/kubelet || return
info "kubelet-config.yaml.template ....."
cat > kubelet-config.yaml.template <<EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: "##NODE_IP##"
staticPodPath: ""
syncFrequency: 1m
fileCheckFrequency: 20s
httpCheckFrequency: 20s
staticPodURL: ""
port: 10250
readOnlyPort: 0
rotateCertificates: true
serverTLSBootstrap: true
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: "/etc/kubernetes/cert/ca.pem"
authorization:
  mode: Webhook
registryPullQPS: 0
registryBurst: 20
eventRecordQPS: 0
eventBurst: 20
enableDebuggingHandlers: true
enableContentionProfiling: true
healthzPort: 10248
healthzBindAddress: "##NODE_IP##"
clusterDomain: "${CLUSTER_DNS_DOMAIN}"
clusterDNS:
  - "${CLUSTER_DNS_SVC_IP}"
nodeStatusUpdateFrequency: 10s
nodeStatusReportFrequency: 1m
imageMinimumGCAge: 2m
imageGCHighThresholdPercent: 85
imageGCLowThresholdPercent: 80
volumeStatsAggPeriod: 1m
kubeletCgroups: ""
systemCgroups: ""
cgroupRoot: ""
cgroupsPerQOS: true
cgroupDriver: cgroupfs
runtimeRequestTimeout: 10m
hairpinMode: promiscuous-bridge
maxPods: 220
podCIDR: "${CLUSTER_CIDR}"
podPidsLimit: -1
resolvConf: /etc/resolv.conf
maxOpenFiles: 1000000
kubeAPIQPS: 1000
kubeAPIBurst: 2000
serializeImagePulls: false
evictionHard:
  memory.available:  "100Mi"
nodefs.available:  "10%"
nodefs.inodesFree: "5%"
imagefs.available: "15%"
evictionSoft: {}
enableControllerAttachDetach: true
failSwapOn: true
containerLogMaxSize: 20Mi
containerLogMaxFiles: 10
systemReserved: {}
kubeReserved: {}
systemReservedCgroup: ""
kubeReservedCgroup: ""
enforceNodeAllocatable: ["pods"]
EOF
```
- -- address: kubelet安全端口(https,10250)监听的地址,不能为127.0.0.1,否则kube-apiserver,heapster等不能调用kubelet的 API
- readOnlyPort=0:关闭只读端口(默认10255),等效为未指定
- authentication.anonymous.enabled:设置为false,不允许匿名访问10250端口
- authentication.x509.clientCAFile:指定签名客户端证书的CA证书,开启HTTP证书认证
- authentication.webhook.enabled=true:开启HTTPs bearer token认证
- 对于未通过x509证书和webhook认证的请求(kube-apiserver或其他客户端),将被拒绝,提示Unauthorized
- authroization.mode=Webhook:kubelet使用 SubjectAccessReview API查询kube-apiserver 某user,group是否具有操作资源的权限(RBAC)
- featureGates.RotateKubeletClientCertificate,featureGates.RotateKubeletServerCertificate:自动rotate证书,证书的有效期取决于kube-controller-manager的--experimental-cluster-signing-duration参数
- 需要 root 账户运行

#### 分发kubelet配置文件

```bash
cd /opt/k8s/certs/kubelet || return
source /opt/k8s/bin/environment.sh
info "deploy kubelet-config.yaml ..... "
for node_ip in "${WORKER_IPS[@]}"
do
    echo ">>> ${node_ip}"
    sed -e "s/##NODE_IP##/${node_ip}/" kubelet-config.yaml.template > kubelet-config-${node_ip}.yaml
    scp kubelet-config-${node_ip}.yaml $k8s_user@${node_ip}:/etc/kubernetes/kubelet-config.yaml
done
```
### 创建分发 kubelet systemd unit

创建 kubelet systemd unit 文件模板:
```bash
info "create kubelet systemd unit ....."
[ ! -d /opt/k8s/services ] && mkdir -p /opt/k8s/services
[ -d /opt/k8s/services/kubelet ] && rm -rf /opt/k8s/services/kubelet
mkdir -p /opt/k8s/services/kubelet
cd /opt/k8s/services/kubelet || return
cat > kubelet.service.template <<EOF
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service
[Service]
WorkingDirectory=${K8S_DIR}/kubelet
ExecStart=/opt/k8s/bin/kubelet \\
  --allow-privileged=true \\
  --bootstrap-kubeconfig=/etc/kubernetes/kubelet-bootstrap.kubeconfig \\
  --cert-dir=/etc/kubernetes/cert \\
  --cni-conf-dir=/etc/cni/net.d \\
  --container-runtime=docker \\
  --container-runtime-endpoint=unix:///var/run/dockershim.sock \\
  --root-dir=${K8S_DIR}/kubelet \\
  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
  --config=/etc/kubernetes/kubelet-config.yaml \\
  --hostname-override=##NODE_NAME## \\
  --pod-infra-container-image=registry.cn-beijing.aliyuncs.com/k8s_images/pause-amd64:3.1 \\
  --image-pull-progress-deadline=15m \\
  --volume-plugin-dir=${K8S_DIR}/kubelet/kubelet-plugins/volume/exec/ \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=${K8S_DIR}/logs/kubelet \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
```
- 如果设置了--hostname-override选项,则kube-proxy也需要设置该选项,否则会出现找不到Node 的情况
- --bootstrap-kubeconfig:指向bootstrap kubeconfig文件,kubelet使用该文件中的用户名和token向kube-apiserver发送TLS Bootstrapping请求
- K8S approve kubelet的csr请求后,在--cert-dir目录创建证书和私钥文件,然后写入--kubeconfig 文件
- --pod-infra-container-image 不使用redhat的 pod-infrastructure:latest 镜像,它不能回收容器的僵尸

为各节点创建和分发 kubelet systemd unit 文件：

```bash
source /opt/k8s/bin/environment.sh
info "deploy kubelet systemd unit ..... "
node_counts=${#WORKER_IPS[@]}
for (( i=0; i < $node_counts; i++ ))
do
    echo ">>> ${WORKER_NAMES[i]}"
    sed -e "s/##NODE_NAME##/${WORKER_NAMES[i]:?}/" kubelet.service.template > kubelet-${WORKER_NAMES[i]:?}.service
    scp kubelet-${WORKER_NAMES[i]:?}.service $k8s_user@${WORKER_IPS[i]:?}:/opt/k8s/kubelet.service
    ssh $k8s_user@${WORKER_IPS[i]:?} "sudo mv /opt/k8s/kubelet.service /etc/systemd/system/"
done
```

#### Bootstrap Token Auth和授予权限

- kublet启动时查找配置的--kubeletconfig文件是否存在,如果不存在则使用--bootstrap-kubeconfig 向kube-apiserver发送证书签名请求(CSR).
- kube-apiserver 收到 CSR 请求后，对其中的 Token 进行认证，认证通过后将请求的 user 设置为 system:bootstrap:<Token ID>，group 设置为 system:bootstrappers，这一过程称为 Bootstrap Token Auth
- 默认情况下,这个user和group没有创建CSR的权限,kubelet启动会失败

解决办法:创建一个clusterrolebinding,将group system:bootstrappers和clusterrole system:node-bootstrapper绑定
```bash
kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers
```
## 启动服务

```bash
source /opt/k8s/bin/environment.sh
info "start kubelet services ..... "
for node_ip in "${WORKER_IPS[@]}"
  do
    echo ">>> ${node_ip}"
    ssh $k8s_user@${node_ip} "sudo mkdir -p ${K8S_DIR}/kubelet&&sudo chown -R $k8s_user ${K8S_DIR}/kubelet"
    ssh $k8s_user@${node_ip} "sudo mkdir -p ${K8S_DIR}/logs/kubelet&&sudo chown -R $k8s_user ${K8S_DIR}/logs/kubelet"
    ssh $k8s_user@${node_ip} "sudo /usr/sbin/swapoff -a"
    ssh $k8s_user@${node_ip} "sudo systemctl daemon-reload && sudo systemctl enable kubelet && sudo systemctl restart kubelet"
  done
```
- 关闭swap分区,否则kubelet会启动失败
- 必须先创建工作和日志目录

kubelet启动后使用--bootstrap-kubeconfig向 kube-apiserver发送CSR请求，当这个CSR被approve后,kube-controller-manager为kubelet创建TLS客户端证书,私钥和 --kubeletconfig文件
==注意:==
kube-controller-manager需要配置 --cluster-signing-cert-file和 --cluster-signing-key-file参数,才会为TLS Bootstrap创建证书和私钥

```bash
kubectl get csr
kubectl get nodes
```
- 三个 work节点的csr均为pending状态

## approve kubelet CSR请求

可以手动或自动approve CSR请求。推荐使用自动的方式,从v1.8版本开始,可以自动轮转approve csr后生成的证书.

### 手动请求


```bash
# 查看CSR列表
kubectl get csr
# node-csr-0r4mCqjJ_tcEM0XdstOwqQo93cviRS1aUd9Fp3cJ-5M   7m57s   system:bootstrap:4wm6u0   Pending
# node-csr-XV0RTnciVGTTp4b19Q_ferk8q8-twi-HY98wss_e0l0   7m59s   system:bootstrap:2deamy   Pending
# node-csr-by8kTLZLZj53qkoLeAB3wAtmuIH5CUCXOX6dDEHhw7U   7m58s   system:bootstrap:qbcnh2   Pending
# approve CSR
kubectl certificate approve node-csr-by8kTLZLZj53qkoLeAB3wAtmuIH5CUCXOX6dDEHhw7U
# certificatesigningrequest.certificates.k8s.io/node-csr-by8kTLZLZj53qkoLeAB3wAtmuIH5CUCXOX6dDEHhw7U approved
# 查看Approve结果
kubectl describe  csr node-csr-by8kTLZLZj53qkoLeAB3wAtmuIH5CUCXOX6dDEHhw7U

# Name:               node-csr-by8kTLZLZj53qkoLeAB3wAtmuIH5CUCXOX6dDEHhw7U
# Labels:             <none>
# Annotations:        <none>
# CreationTimestamp:  Wed, 19 Dec 2018 16:11:20 +0800
# Requesting User:    system:bootstrap:qbcnh2
# Status:             Approved,Issued
# Subject:
#         Common Name:    system:node:k8s-node2
#        Serial Number:
#        Organization:   system:nodes
# Events:  <none>

```
- Requesting User:请求CSR的用户,kube-apiserver对它进行认证和授权
- Subject:请求签名的证书信息
- 证书的CN是system:node:k8s-node2
Organization是system:nodes,kube-apiserver 的Node授权模式会授予该证书的相关权限

### 自动请求

创建三个ClusterRoleBinding,分别用于自动approve client,renew client,renew server证书.
脚本:07.03.auto-approve-csr.sh

- auto-approve-csrs-for-group:自动approve node 的第一次CSR;注意第一次CSR时,请求的Group为system:bootstrappers
- node-client-cert-renewal:自动approve node后续过期的client证书,自动生成的证书Group为system:nodes
- node-server-cert-renewal:自动approve node后续过期的server证书,自动生成的证书 Group为system:nodes

## 查看kublet的情况

等待一段时间(1-10 分钟),三个节点的CSR都被自动approve

```bash
kubectl get csr
```
所有节点均ready

```bash
kubectl get nodes
```
kube-controller-manager为各node生成了 kubeconfig文件和公私钥

```bash
ls -l /etc/kubernetes/kubelet.kubeconfig
ls -l /etc/kubernetes/cert/|grep kubelet
```

## kubelet提供的API接口

kublet启动后监听多个端口,用于接收kube-apiserver或其它组件发送的请求

```bash
sudo netstat -lnpt|grep kubelet

# tcp        0      0 10.0.1.17:10248         0.0.0.0:*               LISTEN      15386/kubelet
# tcp        0      0 10.0.1.17:10250         0.0.0.0:*               LISTEN      15386/kubelet
# tcp        0      0 127.0.0.1:33135         0.0.0.0:*               LISTEN      15386/kubelet
```
- 10248: healthz http服务
- 10250:https服务,访问该端口时需要认证和授权(即使访问 /healthz 也需要)
- 从K8S v1.10开始,去除了--cadvisor-port参数(默认 4194 端口),不支持访问 cAdvisor UI & API
- ==注意:==未开启只读端口10255

例如执行==kubectl ec -it nginx-ds-5rmws -- sh==命令时,kube-apiserver会向kubelet发送如下请求:


```bash
POST /exec/default/nginx-ds-5rmws/my-nginx?command=sh&input=1&output=1&tty=1
```
kubelet接收10250端口的https请求:

- /pods,/runningpods
- /metrics,/metrics/cadvisor,/metrics/probes
- /spec
- /stats,/stats/container
- /logs
- /run/,"/exec/","/attach/","/portForward/","/containerLogs/"等管理

详情参考:https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/server/server.go#L434:3

由于关闭了匿名认证,同时开启了webhook授权,所有访问10250端口https API的请求都需要被认证和授权.

预定义的ClusterRole system:kubelet-api-admin授予访问kubelet所有API的权限.

```bash
kubectl describe clusterrole system:kubelet-api-admin
```

## kublet api认证和授权

kublet配置了如下认证参数:
- authentication.anonymous.enabled:设置为 false,不允许匿名访问10250端口
- authentication.x509.clientCAFile:指定签名客户端证书的CA证书,开启HTTPs证书认证
- authentication.webhook.enabled=true:开启HTTPs bearer token认证
-
同时配置了如下授权参数：
- authroization.mode=Webhook:开启RBAC授权

kubelet收到请求后,使用clientCAFile对证书签名进行认证,或者查询bearer token是否有效.如果两者都没通过,则拒绝请求,提示Unauthorized


```bash
curl -s --cacert /etc/kubernetes/cert/ca.pem https://10.0.1.17:10250/metrics

curl -s --cacert /etc/kubernetes/cert/ca.pem -H "Authorization: Bearer 123456" https://10.0.1.17:10250/metrics
```

通过认证后,kubelet使用SubjectAccessReview API向kube-apiserver发送请求,查询证书或 token对应的user,group是否有操作资源的权限(RBAC)

## 证书认证和授权:

```bash
# 权限不足的证书；
curl -s --cacert /etc/kubernetes/cert/ca.pem --cert /etc/kubernetes/cert/kube-controller-manager.pem --key /etc/kubernetes/cert/kube-controller-manager-key.pem https://10.0.1.17:10250/metrics
Forbidden (user=system:kube-controller-manager, verb=get, resource=nodes, subresource=metrics)

# 使用部署 kubectl 命令行工具时创建的、具有最高权限的 admin 证书；
curl -s --cacert /etc/kubernetes/cert/ca.pem --cert ./admin.pem --key ./admin-key.pem https://192.168.3.23:10250/metrics| head
```

- --cacert,--cert,--key的参数值必须是文件路径,如上面的./admin.pem不能省略./,否则返回 401 Unauthorized

## bear token认证和授权
创建一个ServiceAccount,将它和ClusterRole system:kubelet-api-admin绑定,从而具有调用 kubelet API 的权限：

```bash
kubectl create sa kubelet-api-test
kubectl create clusterrolebinding kubelet-api-test --clusterrole=system:kubelet-api-admin --serviceaccount=default:kubelet-api-test
SECRET=$(kubectl get secrets | grep kubelet-api-test | awk '{print $1}')
TOKEN=$(kubectl describe secret ${SECRET} | grep -E '^token' | awk '{print $2}')
echo ${TOKEN}

curl -s --cacert /etc/kubernetes/cert/ca.pem -H "Authorization: Bearer ${TOKEN}" https://192.168.3.23:10250/metrics|head
```
## cadvisor和metrics

cadvisor统计所在节点各容器的资源(CPU,内存,磁盘,网卡)使用情况,分别在自己的http web页面(4194 端口)和10250以promehteus metrics的形式输出
浏览器访问 http://192.168.3.23:4194/containers/ 可以查看到 cadvisor 的监控页面

浏览器访问 https://192.168.3.28:10250/metrics 和https://192.168.3.28:10250/metrics/cadvisor 分别返回kublet和 cadvisor 的metrics

==注意:==
- kublet.config.json设置authentication.anonymous.enabled为false,不允许匿名证书访问10250的https 服务
- 参考A.浏览器访问kube-apiserver安全端口.md,创建和导入相关证书,然后访问上面的 10250端口

## 获取kublet的配置

从kube-apiserver获取各node的配置

```bash
# 使用部署kubectl命令行工具时创建的,具有最高权限的admin证书
source /opt/k8s/bin/environment.sh
curl -sSL --cacert /etc/kubernetes/cert/ca.pem --cert ./admin.pem --key ./admin-key.pem ${KUBE_APISERVER}/api/v1/nodes/k8s-node1/proxy/configz | jq \
'.kubeletconfig|.kind="KubeletConfiguration"|.apiVersion="kubelet.config.k8s.io/v1beta1"'
```
或者参考代码中的注释:https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/kubeletconfig/v1beta1/types.go

==参考==
kubelet认证和授权:https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/
