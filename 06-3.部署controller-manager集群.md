# 06-3.部署controller-manager集群

该集群包含3个节点,启动后将通过竞争选举机制产生一个leader节点,其它节点为阻塞状态.当leader节点不可用后,剩余节点将再次进行选举产生新的leader 节点,从而保证服务的可用性。

为保证通信安全,生成x509证书和私钥,kube-controller-manager在如下两种情况下使用该证书:
- 与kube-apiserver的安全端口通信
- 在安全端口(https,10252)输出prometheus格式的 metrics

如果多个master节点上的相关服务同时生效，则会有同步与一致性问题,所以多master节点中的kube-controller-manager服务只能是主备的关系,kukubernetes采用租赁锁(lease-lock)实现leader的选举,具体到kube-controller-manager,设置启动参数"--leader-elect=true".

## 准备工作
下载最新版本的二进制文件,安装和配置flanneld
参考:
1. 06-0.master节点部署
2. 05.flannel网络部署

## 创建kube-controller-manager证书和私钥
脚本:06.08.controller-manager-cert.sh

创建证书签名请求：

```bash
mkdir -p /opt/k8s/ssl/kube-controller-manager
cd /opt/k8s/ssl/kube-controller-manager
cat > kube-controller-manager-csr.json <<EOF
{
    "CN": "system:kube-controller-manager",
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "hosts": [
      "127.0.0.1",
      "192.168.3.23",
      "192.168.3.26",
      "192.168.3.28"
    ],
    "names": [
      {
        "C": "CN",
        "ST": "Beijing",
        "L": "Beijing",
        "O": "system:kube-controller-manager",
        "OU": "k8s"
      }
    ]
}
EOF
```
- hosts列表包含所有kube-controller-manager节点IP
- CN和O均为system:kube-controller-manager,kubernetes内置的 ClusterRoleBindings system:kube-controller-manager 赋予 kube-controller-manager 工作所需的权限

## kube-controller-manager 初始化
脚本:

### kubeconfig文件

kubeconfig文件包含访问apiserver的所有信息,如 apiserver地址,CA证书和自身使用的证书


```bash
source /opt/k8s/bin/environment.sh
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/cert/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-controller-manager.kubeconfig

kubectl config set-credentials system:kube-controller-manager \
  --client-certificate=kube-controller-manager.pem \
  --client-key=kube-controller-manager-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-controller-manager.kubeconfig

kubectl config set-context system:kube-controller-manager \
  --cluster=kubernetes \
  --user=system:kube-controller-manager \
  --kubeconfig=kube-controller-manager.kubeconfig

kubectl config use-context system:kube-controller-manager --kubeconfig=kube-controller-manager.kubeconfig

```
分发kubeconfig到所有master节点
```bash
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp kube-controller-manager.kubeconfig ak47@${node_ip}:/etc/kubernetes/
  done
```

### kube-controller-manager systemd unit 文件

```bash
source /opt/k8s/bin/environment.sh
cat > kube-controller-manager.service <<EOF
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
WorkingDirectory=${K8S_DIR}/kube-controller-manager
ExecStart=/opt/k8s/bin/kube-controller-manager \\
  --profiling \\
  --bind-address=##NODE_IP## \\
  --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --authentication-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --authorization-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\
  --service-cluster-ip-range=${SERVICE_CIDR} \\
  --cluster-name=kubernetes \\
  --cluster-signing-cert-file=/etc/kubernetes/cert/ca.pem \\
  --cluster-signing-key-file=/etc/kubernetes/cert/ca-key.pem \\
  --experimental-cluster-signing-duration=876000h \\
  --root-ca-file=/etc/kubernetes/cert/ca.pem \\
  --service-account-private-key-file=/etc/kubernetes/cert/ca-key.pem \\
  --kube-api-qps=1000 \\
  --kube-api-burst=2000 \\
  --leader-elect \\
  --use-service-account-credentials \\
  --concurrent-service-syncs=2 \\
  --concurrent-deployment-syncs=10 \\
  --concurrent-gc-syncs=30 \\
  --node-cidr-mask-size=24 \\
  --pod-eviction-timeout=6m \\
  --terminated-pod-gc-threshold=10000 \\
  --tls-cert-file=/etc/kubernetes/cert/kube-controller-manager.pem \\
  --tls-private-key-file=/etc/kubernetes/cert/kube-controller-manager-key.pem \\
  --client-ca-file=/etc/kubernetes/cert/ca.pem \\
  --requestheader-allowed-names="" \\
  --requestheader-client-ca-file=/etc/kubernetes/cert/aggregator-ca.pem \\
  --requestheader-extra-headers-prefix="X-Remote-Extra-" \\
  --requestheader-group-headers=X-Remote-Group \\
  --requestheader-username-headers=X-Remote-User \\
  --feature-gates=RotateKubeletServerCertificate=true \\
  --controllers=*,bootstrapsigner,tokencleaner \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=${K8S_DIR}/logs/kubernetes \\
  --secure-port=10252 \\
  --port=0 \\
  --horizontal-pod-autoscaler-use-rest-clients=true \\
  --horizontal-pod-autoscaler-sync-period=10s \\
  --v=2
Restart=on-failure
RestartSec=5
User=$k8s_user

[Install]
WantedBy=multi-user.target
EOF
```
- \--profiling: 设置为true 表示打开性能分析功能，默认值为true,访问地址:<host>:<port>/debug/pprof
- \--bind-address:在https端口提供服务时监听的ip地址,默认为0.0.0.0
- \--port=0：关闭监听http /metrics的请求,同时 --address参数无效,--bind-address 参数有效(已弃用的参数)
- \--kubeconfig:指定kubeconfig文件路径,kube-controller-manager使用它连接和验证kube-apiserver
- \--authentication-kubeconfig和--authorization-kubeconfig:kube-controller-manager 使用它连接 apiserver，对 client 的请求进行认证和授权。kube-controller-manager 不再使用 --tls-ca-file 对请求 https metrics 的 Client 证书进行校验。如果没有配置这两个 kubeconfig 参数，则 client 连接 kube-controller-manager https 端口的请求会被拒绝(提示权限不足)
- \--service-cluster-ip-range:指定Service ClusterIP网段,必须和kube-apiserver中的同名参数一致
- \--cluster-name:The instance prefix for the cluster. 默认值 "kubernetes"
- \--cluster-signing-*-file：签名 TLS Bootstrap 创建的证书
- \--experimental-cluster-signing-duration:指定TLS Bootstrap证书的有效期
- \--root-ca-file:放置到容器ServiceAccount中的CA证书,用来对kube-apiserver的证书进行校验
- \--service-account-private-key-file:签名ServiceAccount中Token的私钥文件,必须和kube-apiserver的--service-account-key-file指定的公钥文件配对使用
- \--kube-api-qps:与 API Server 通信的QPS值,默认值为20
- \--kube-api-burst:发送到API Server 的每秒请求数量，默认值为30
- \--leader-elect=true:集群运行模式,启用选举功能,被选为leader的节点负责处理工作,其它节点为阻塞状态
- \--use-service-account-credentials=true: kube-controller-manager 中各controller使用serviceaccount访问kube-apiserver
- \--concurrent-service-syncs:设置允许的并发同步Service对象的数量,值越大表示同步操作越快,默认值为1
- \--concurrent-deployment-syncs:设置允许的并发同步Deployment对象的数量,值越大表示同步操作越快,默认值为5
- \--concurrent-gc-syncs:设置并发执行GC Worker 的数量 默认值为20
- \--node-cidr-mask-size:Node CIDR 的子网掩码设置，默认值24
- \--pod-eviction-timeout:在失效Node上删除Pod的超时时间,默认值为5m0s
- \--terminated-pod-gc-threshold:设置可保存的终止Pod数量,超过该数量时,垃圾回收器将进行删除操作。设置为不大于0表示不启用此功能,默认值为12500
- \--tls-cert-file,--tls-private-key-file:使用https输出metrics时使用的Server证书和秘钥
- \--client-ca-file:如果未指定，则该客户端证书将不用于认证
- \--feature-gates=RotateKubeletServerCertificate=true:开启kublet server证书的自动更新特性
- \--controllers=\*,bootstrapsigner,tokencleaner:启用的控制器列表,tokencleaner用于自动清理过期的Bootstrap token
- \--horizontal-pod-autoscaler-*:custom metrics相关参数,支持 autoscaling/v2alpha1 (已废弃参数)
- \--horizontal-pod-autoscaler-sync-period:pod 自动扩容器的pod数量的同步时间间隔,默认值为30s(已废弃参数)
- \--secure-port=10252  在所有网络接口监听10252端口的https /metrics请求
- \--port=0：关闭监听非安全端口（http），同时 --address 参数无效，--bind-address 参数有效
- \User=ak47:使用ak47账户运行

==注意:==
kube-controller-manager不对请求https metrics 的Client证书进行校验,故不需要指定--tls-ca-file参数,而且该参数已被淘汰
### kube-controller-manager 的权限
ClusteRole: system:kube-controller-manager 的权限很小，只能创建 secret、serviceaccount 等资源对象，各 controller 的权限分散到 ClusterRole system:controller:XXX 中。

需要在 kube-controller-manager 的启动参数中添加 --use-service-account-credentials=true 参数，这样 main controller 会为各 controller 创建对应的 ServiceAccount XXX-controller。

内置的 ClusterRoleBinding system:controller:XXX 将赋予各 XXX-controller ServiceAccount 对应的 ClusterRole system:controller:XXX 权限。

### 启动服务
```bash
source /opt/k8s/bin/environment.sh
for node_ip in "${MASTER_IPS[@]}"
do
    echo ">>> ${node_ip}"
    ssh $k8s_user@${node_ip} "sudo mkdir -p ${K8S_DIR}/kube-controller-manager && sudo chown -R $k8s_user ${K8S_DIR}/kube-controller-manager"
    ssh $k8s_user@${node_ip} "sudo mkdir -p ${K8S_DIR}/logs/kube-controller-manager && sudo chown -R $k8s_user ${K8S_DIR}/logs/kube-controller-manager"
    scp kube-controller-manager-${node_ip}.service $k8s_user@${node_ip}:/opt/k8s/kube-controller-manager.service
    ssh $k8s_user@${node_ip} "sudo mv /opt/k8s/kube-controller-manager.service /etc/systemd/system/kube-controller-manager.service"
done

for node_ip in "${MASTER_IPS[@]}"
  do
    echo ">>> ${node_ip}"
    ssh $k8s_user@${node_ip} "sudo systemctl daemon-reload && sudo systemctl stop kube-controller-manager "
    ssh $k8s_user@${node_ip} "sudo systemctl daemon-reload && sudo systemctl enable kube-controller-manager && sudo systemctl restart kube-controller-manager"
  done
```
- 启动服务前必须先创建工作目录
-
## 检查服务运行状态

```bash
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    ssh $k8s_user@${node_ip} "sudo systemctl status kube-controller-manager|grep Active"
  done
# 确保状态为 active (running) 否则查看日志
sudo journalctl -u kube-controller-manager -f
# kube-controller-manager监听10252端口,接收 https请求：
sudo netstat -lnpt|grep kube-controll
```
## 查看输出的metric

==注意:== 以下命令在kube-controller-manager 节点上执行
```bash
curl -s --cacert /etc/kubernetes/cert/ca.pem --cert /opt/k8s/certs/admin/admin.pem --key /opt/k8s/certs/admin-key.pem https://10.0.1.17:10252/metrics |head
curl -s --cacert /etc/kubernetes/cert/ca.pem https://10.0.1.17:10252/metrics |head
# or
curl -s http://127.0.0.1:10252/metrics |head
```
## 检查集群信息

```bash
kubectl cluster-info
# Kubernetes master is running at https://192.168.3.253:8443
kubectl get all --all-namespaces
kubectl get componentstatuses
```
## 测试集群的高可用

停掉一个或两个节点的kube-controller-manager 服务,观察其它节点的日志,看是否获取了leader权限

查看当前的leader

```bash
kubectl get endpoints kube-controller-manager --namespace=kube-system  -o yaml
```

## 参考

1. controller权限和use-service-account-credentials参数:
https://github.com/kubernetes/kubernetes/issues/48208
2. kublet 认证和授权:
https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authorization
